{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2022-08-05 02:03:11,616] [    INFO]\u001B[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\vocab.json and saved to C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,617] [    INFO]\u001B[0m - Found C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\\vocab.json\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,620] [    INFO]\u001B[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\merges.txt and saved to C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,621] [    INFO]\u001B[0m - Found C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\\merges.txt\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,623] [    INFO]\u001B[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\added_tokens.json and saved to C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,625] [    INFO]\u001B[0m - Found C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\\added_tokens.json\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,627] [    INFO]\u001B[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\special_tokens_map.json and saved to C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,628] [    INFO]\u001B[0m - Found C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\\special_tokens_map.json\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,630] [    INFO]\u001B[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\tokenizer_config.json and saved to C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,632] [    INFO]\u001B[0m - Downloading tokenizer_config.json from https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\tokenizer_config.json\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,903] [    INFO]\u001B[0m - Adding                                 to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,906] [    INFO]\u001B[0m - Adding                                to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,907] [    INFO]\u001B[0m - Adding                               to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,907] [    INFO]\u001B[0m - Adding                              to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,908] [    INFO]\u001B[0m - Adding                             to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,909] [    INFO]\u001B[0m - Adding                            to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,910] [    INFO]\u001B[0m - Adding                           to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,911] [    INFO]\u001B[0m - Adding                          to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,912] [    INFO]\u001B[0m - Adding                         to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,913] [    INFO]\u001B[0m - Adding                        to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,913] [    INFO]\u001B[0m - Adding                       to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,914] [    INFO]\u001B[0m - Adding                      to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,915] [    INFO]\u001B[0m - Adding                     to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,916] [    INFO]\u001B[0m - Adding                    to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,917] [    INFO]\u001B[0m - Adding                   to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,918] [    INFO]\u001B[0m - Adding                  to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,919] [    INFO]\u001B[0m - Adding                 to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,920] [    INFO]\u001B[0m - Adding                to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,921] [    INFO]\u001B[0m - Adding               to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,922] [    INFO]\u001B[0m - Adding              to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,923] [    INFO]\u001B[0m - Adding             to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,924] [    INFO]\u001B[0m - Adding            to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,925] [    INFO]\u001B[0m - Adding           to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,926] [    INFO]\u001B[0m - Adding          to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,927] [    INFO]\u001B[0m - Adding         to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,928] [    INFO]\u001B[0m - Adding        to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,928] [    INFO]\u001B[0m - Adding       to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,929] [    INFO]\u001B[0m - Adding      to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,930] [    INFO]\u001B[0m - Adding     to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,931] [    INFO]\u001B[0m - Adding    to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,932] [    INFO]\u001B[0m - Adding \t\t\t\t\t\t\t\t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,932] [    INFO]\u001B[0m - Adding \t\t\t\t\t\t\t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,933] [    INFO]\u001B[0m - Adding \t\t\t\t\t\t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,934] [    INFO]\u001B[0m - Adding \t\t\t\t\t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,935] [    INFO]\u001B[0m - Adding \t\t\t\t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,937] [    INFO]\u001B[0m - Adding \t\t\t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,938] [    INFO]\u001B[0m - Adding \t\t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,939] [    INFO]\u001B[0m - Adding \t\t to the vocabulary\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,942] [    INFO]\u001B[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\model_state.pdparams and saved to C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,944] [    INFO]\u001B[0m - Found C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\\model_state.pdparams\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,946] [    INFO]\u001B[0m - Downloading https://bj.bcebos.com/paddlenlp/models/community/Salesforce/codegen-350M-mono\\model_config.json and saved to C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\u001B[0m\n",
      "\u001B[32m[2022-08-05 02:03:11,947] [    INFO]\u001B[0m - Found C:\\Users\\JiaMing Liang\\.paddlenlp\\models\\Salesforce/codegen-350M-mono\\model_config.json\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import paddle\n",
    "from paddlenlp.transformers import CodeGenTokenizer, CodeGenForCausalLM\n",
    "\n",
    "# The supported models are shown in the following table\n",
    "model_name = 'Salesforce/codegen-350M-mono'\n",
    "# Init tokenizer\n",
    "tokenizer = CodeGenTokenizer.from_pretrained(model_name)\n",
    "# Init model\n",
    "model = CodeGenForCausalLM.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[4299, 2160, 7, 64, 11, 65, 2599]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([\"def sum(a,b):\"])\n",
    "print(inputs)\n",
    "inputs = {k: paddle.to_tensor(v) for (k, v) in inputs.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    return a + b\n",
      "speed time 11.97002387046814\n"
     ]
    }
   ],
   "source": [
    "# Generate\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "output, score = model.generate(inputs['input_ids'],\n",
    "                               max_length=128,\n",
    "                               decode_strategy='sampling',\n",
    "                               top_k=5,\n",
    "                               repetition_penalty=1.1,\n",
    "                               temperature=0.6,\n",
    "                               use_faster=True)\n",
    "# Decode the result\n",
    "print(\n",
    "    re.split(\n",
    "        \"\\nclass|\\ndef|\\n#|\\n@|\\nprint|\\nif\",\n",
    "        tokenizer.decode(output[0],\n",
    "                         skip_special_tokens=True,\n",
    "                         spaces_between_special_tokens=False))[0].rstrip())\n",
    "print(\"speed time \" + str(time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}